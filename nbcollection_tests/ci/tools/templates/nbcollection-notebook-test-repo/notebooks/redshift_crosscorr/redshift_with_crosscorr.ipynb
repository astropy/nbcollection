{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring galaxy redshift with cross-correlation algorithm\n",
    "\n",
    "This notebook attempts to follow the workflow that uses IRAF tasks, described here http://tdc-www.harvard.edu/iraf/rvsao/xcsao/xcsao.proc.html\n",
    "\n",
    "Observed spectrum from LEGA-C: LEGA-C is a galaxy survey of about 3000 galaxies at z~0.8 and M* > 10^10 M_sun in the COSMOS field. The spectra sample the rest-frame optical between ~3000A and 5000A at high resolution and very high signal-to-noise ratio. More information about the survey can be found here: http://www.mpia.de/home/legac/\n",
    "\n",
    "Template from Pacifici et al. 2012.\n",
    "\n",
    "**Developer Notes:**\n",
    "    - This workflow will be rendered in a few simple clicks in specviz\n",
    "    - Preparing the template outside the correlation function allows for applications to different science cases\n",
    "\n",
    "Author: Ivo Busko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal.windows import tukey\n",
    "import astropy\n",
    "import astropy.units as u\n",
    "from astropy.table import QTable\n",
    "from astropy.nddata import StdDevUncertainty\n",
    "from astropy.modeling.polynomial import Chebyshev1D\n",
    "from astropy import constants as const\n",
    "from astropy.io import fits, ascii\n",
    "\n",
    "import specutils\n",
    "from specutils.fitting import continuum, find_lines_threshold, find_lines_derivative\n",
    "from specutils.spectra.spectrum1d import Spectrum1D\n",
    "from specutils.manipulation.resample import FluxConservingResampler, \\\n",
    "    SplineInterpolatedResampler, LinearInterpolatedResampler\n",
    "from specutils.analysis import correlation\n",
    "from specutils.spectra.spectral_region import SpectralRegion\n",
    "from specutils.manipulation.extract_spectral_region import extract_region\n",
    "from specutils.manipulation.utils import linear_exciser\n",
    "from specutils.manipulation import noise_region_uncertainty\n",
    "from specutils.manipulation import gaussian_smooth\n",
    "\n",
    "# Check versions\n",
    "print(\"Numpy: \",np.__version__)\n",
    "print(\"Astropy: \",astropy.__version__)\n",
    "print(\"Specutils: \",specutils.__version__)\n",
    "print(\"\")\n",
    "print(\"They should be:\")\n",
    "print(\"Numpy:  1.18.1\")\n",
    "print(\"Astropy:  4.0\")\n",
    "print(\"Specutils:  1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib setup for plotting\n",
    "There are two versions\n",
    " - `notebook` -- gives interactive plots, but makes the overall notebook a bit harder to scroll\n",
    " - `inline` -- gives non-interactive plots for better overall scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Use this version for non-interactive plots (easier scrolling of the notebook)\n",
    "%matplotlib inline\n",
    "\n",
    "# Use this version if you want interactive plots\n",
    "# %matplotlib notebook\n",
    "\n",
    "# These gymnastics are needed to make the sizes of the figures\n",
    "# be the same in both the inline and notebook versions\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches': None}\n",
    "\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files are on box\n",
    "\n",
    "# Observation and weight.\n",
    "file1d = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/redshift_crosscorr/legac_M1_v3.7_spec1d_130902.fits'\n",
    "file1dwht = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/redshift_crosscorr/legac_M1_v3.7_wht1d_130902.fits'\n",
    "# Template.\n",
    "template_file = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/redshift_crosscorr/00006.dat'\n",
    "\n",
    "# Plot limits\n",
    "sp_xlim = [3000., 9000.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read observation and template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation\n",
    "hdu1d = fits.open(file1d)\n",
    "hdu1dwht = fits.open(file1dwht)\n",
    "\n",
    "flux = hdu1d[0].data\n",
    "wht = hdu1dwht[0].data\n",
    "unc = 1./ np.sqrt(wht)\n",
    "wave = np.arange(flux.shape[0])*hdu1d[0].header['CD1_1'] + hdu1d[0].header['CRVAL1']\n",
    "\n",
    "spec_unit = u.Unit('10^-19 erg s^-1 cm^-2 angstrom^-1')\n",
    "dataspec = QTable([wave*u.angstrom, flux*spec_unit, wht, unc*spec_unit], \n",
    "                   names=('wavelength','flux','weight','uncertainty'))\n",
    "dataspec_sub = dataspec[dataspec['weight']>0.]\n",
    "dataspec_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now make it into a Spectrum1D instance.\n",
    "obs = Spectrum1D(spectral_axis=dataspec_sub['wavelength'], \n",
    "                 flux=dataspec_sub['flux'], \n",
    "                 uncertainty=StdDevUncertainty(dataspec_sub['uncertainty']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template\n",
    "template = ascii.read(template_file)\n",
    "factor = 2.E-5 * obs.flux.unit # normalize template to a sensible range\n",
    "template = Spectrum1D(spectral_axis=template['col1']*u.AA, \n",
    "                      flux=template['col2']*factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that in this and in subsequent plots, we are showing just the wavelength range of\n",
    "# interest. The template covers a significantly wider range.\n",
    "pl.figure()\n",
    "pl.gcf().set_size_inches((8.,4.))\n",
    "pl.xlim(sp_xlim)\n",
    "pl.plot(obs.wavelength, obs.flux, linewidth=0.5, label='obs')\n",
    "pl.plot(template.wavelength, template.flux, linewidth=0.5, color='r', label='template')\n",
    "pl.legend()\n",
    "pl.title('Input data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtract continuum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuum_model = continuum.fit_generic_continuum(obs) \n",
    "p_obs = obs - continuum_model(obs.wavelength)\n",
    "continuum_model = continuum.fit_generic_continuum(template, model=Chebyshev1D(5)) \n",
    "p_template = template - continuum_model(template.wavelength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure()\n",
    "pl.gcf().set_size_inches((8.,4.))\n",
    "pl.xlim(sp_xlim)\n",
    "pl.plot(p_obs.wavelength, p_obs.flux, linewidth=0.5, label='obs')\n",
    "pl.plot(p_template.wavelength, p_template.flux, linewidth=0.5, color='r', label='template')\n",
    "pl.legend()\n",
    "pl.title('After continuum subtraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IRAF task XCORR works in Fourier space. In there, it applies a cosine bell filter (raised-cosine filter) to the observed spectrum, before multiplying together the two Fourier transforms. Here, we are working in data space, thus we emulate the filter operation by convolving the observed spectrum with a windowed sinc smoothing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Smooth data with sinc kernel\n",
    "fc = 0.25  # Cutoff frequency as a fraction of the sampling rate (in (0, 0.5)).\n",
    "b = 0.49   # Transition band, as a fraction of the sampling rate (in (0, 0.5)).\n",
    "\n",
    "# The IRAF task uses the above values. Here, we try\n",
    "# a much lower cutoff frequency to really dampen the\n",
    "# high frequency structure in the observed spectrum.\n",
    "fc = 0.05 \n",
    "\n",
    "N = int(np.ceil((4 / b)))\n",
    "if not N % 2:  # N must be odd\n",
    "    N += 1\n",
    "n = np.arange(N)\n",
    " \n",
    "# Compute sinc filter and Blackman window. Multiply filter \n",
    "# by window and normalize to get unity gain.\n",
    "filt = np.sinc(2 * fc * (n - (N - 1) / 2))\n",
    "w = 0.42 - 0.5 * np.cos(2 * np.pi * n / (N - 1)) + \\\n",
    "    0.08 * np.cos(4 * np.pi * n / (N - 1))\n",
    "filt *= w\n",
    "filt /= np.sum(filt)\n",
    "\n",
    "# Smooth\n",
    "sflux = np.convolve(p_obs.flux, filt, mode='same')\n",
    "\n",
    "p_obs = Spectrum1D(spectral_axis=p_obs.wavelength,\n",
    "                   flux=sflux,\n",
    "                   uncertainty=p_obs.uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure()\n",
    "pl.gcf().set_size_inches((8.,4.))\n",
    "pl.xlim(sp_xlim)\n",
    "pl.plot(p_obs.wavelength, p_obs.flux, linewidth=0.5, label='obs')\n",
    "pl.plot(p_template.wavelength, p_template.flux, linewidth=0.5, color='r', label='template')\n",
    "pl.legend()\n",
    "pl.title('After smoothing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Correlation. \n",
    "#\n",
    "# With no additional specifications, both the entire template and entire spectrum \n",
    "# will be included in the correlation computation. This in general will incur in \n",
    "# a significant increase in execution time. It is advised that the template is cut\n",
    "# to work only on the useful region.\n",
    "\n",
    "corr, lag = correlation.template_correlate(p_obs, p_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure()\n",
    "pl.gcf().set_size_inches((8.,4.))\n",
    "pl.plot(lag, corr, linewidth=0.5)\n",
    "pl.xlim(0,300000)\n",
    "pl.xlabel(lag.unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redshift based on maximum\n",
    "index_peak = np.where(corr == np.amax(corr))[0][0]\n",
    "v = lag[index_peak]\n",
    "z = v / const.c.to('km/s')\n",
    "print(\"Peak maximum at: \", v)\n",
    "print(\"Redshift from peak maximum: \", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit correlation peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redshift based on parabolic fit to mazimum\n",
    "\n",
    "n = 8 # points to the left or right of correlation maximum\n",
    "\n",
    "peak_lags = lag[index_peak-n:index_peak+n+1].value\n",
    "peak_vals = corr[index_peak-n:index_peak+n+1].value\n",
    "p = np.polyfit(peak_lags, peak_vals, deg=2)\n",
    "roots = np.roots(p)\n",
    "\n",
    "v_fit = np.mean(roots) * u.km/u.s # maximum lies at mid point between roots\n",
    "z = v_fit / const.c.to('km/s')\n",
    "\n",
    "print(\"Parabolic fit with maximum at: \", v_fit)\n",
    "print(\"Redshift from parabolic fit: \", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pl.figure()\n",
    "pl.gcf().set_size_inches((8.,4.))\n",
    "# pl.xlim(sp_xlim)\n",
    "pl.scatter(peak_lags, peak_vals, label='data')\n",
    "pl.plot(peak_lags, np.polyval(p, peak_lags), linewidth=0.5, label='fit')\n",
    "pl.xlabel(lag.unit)\n",
    "pl.legend()\n",
    "pl.title('Fit to correlation peak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ref = 0.758 # \"true\" redshift, corresponding to 227242.6 km/s\n",
    "\n",
    "template_z = Spectrum1D(spectral_axis=template.wavelength * (1.+z), flux=template.flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pl.figure()\n",
    "pl.gcf().set_size_inches((8.,4.))\n",
    "pl.xlim(sp_xlim)\n",
    "pl.plot(obs.wavelength, obs.flux, linewidth=0.5, label='obs')\n",
    "pl.plot(template_z.wavelength, template_z.flux, linewidth=0.5, color='r', label='template')\n",
    "pl.legend()\n",
    "pl.title('Redshifted original template and original observed spectrum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_err = (z - z_ref) / z_ref * 100.\n",
    "print(\"Error in the derived redshift: \", z_err, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case with lower resolution observed spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read observation and template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation\n",
    "hdu1d = fits.open(file1d)\n",
    "hdu1dwht = fits.open(file1dwht)\n",
    "\n",
    "flux = hdu1d[0].data\n",
    "wht = hdu1dwht[0].data\n",
    "unc = 1./ np.sqrt(wht)\n",
    "wave = np.arange(flux.shape[0])*hdu1d[0].header['CD1_1'] + hdu1d[0].header['CRVAL1']\n",
    "\n",
    "spec_unit = u.Unit('10^-19 erg s^-1 cm^-2 angstrom^-1')\n",
    "dataspec = QTable([wave*u.angstrom, flux*spec_unit, wht, unc*spec_unit], \n",
    "                   names=('wavelength','flux','weight','uncertainty'))\n",
    "dataspec_sub = dataspec[dataspec['weight']>0.]\n",
    "dataspec_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now make it into a Spectrum1D instance.\n",
    "obs_orig = Spectrum1D(spectral_axis=dataspec_sub['wavelength'], \n",
    "                 flux=dataspec_sub['flux'], \n",
    "                 uncertainty=StdDevUncertainty(dataspec_sub['uncertainty']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change resolution of spectrum\n",
    "obs = gaussian_smooth(obs_orig, stddev=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template\n",
    "template = ascii.read(template_file)\n",
    "factor = 2.E-5 * obs.flux.unit # normalize template to a sensible range\n",
    "template = Spectrum1D(spectral_axis=template['col1']*u.AA, \n",
    "                      flux=template['col2']*factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that in this and in subsequent plots, we are showing just the wavelength range of\n",
    "# interest. The template covers a significantly wider range.\n",
    "pl.figure()\n",
    "pl.gcf().set_size_inches((8.,4.))\n",
    "pl.xlim(sp_xlim)\n",
    "pl.plot(obs.wavelength, obs.flux, linewidth=0.5, label='obs')\n",
    "pl.plot(template.wavelength, template.flux, linewidth=0.5, color='r', label='template')\n",
    "pl.legend()\n",
    "pl.title('Input data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Spectra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtract continuum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuum_model = continuum.fit_generic_continuum(obs) \n",
    "p_obs = obs - continuum_model(obs.wavelength)\n",
    "continuum_model = continuum.fit_generic_continuum(template, model=Chebyshev1D(5)) \n",
    "p_template = template - continuum_model(template.wavelength)\n",
    "\n",
    "pl.figure()\n",
    "pl.gcf().set_size_inches((8.,4.))\n",
    "pl.xlim(sp_xlim)\n",
    "pl.plot(p_obs.wavelength, p_obs.flux, linewidth=0.5, label='obs')\n",
    "pl.plot(p_template.wavelength, p_template.flux, linewidth=0.5, color='r', label='template')\n",
    "pl.legend()\n",
    "pl.title('After continuum subtraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth data with sinc kernel\n",
    "fc = 0.25  # Cutoff frequency as a fraction of the sampling rate (in (0, 0.5)).\n",
    "b = 0.49   # Transition band, as a fraction of the sampling rate (in (0, 0.5)).\n",
    "\n",
    "# The IRAF task uses the above values. Here, we try\n",
    "# a much lower cutoff frequency to really dampen the\n",
    "# high frequency structure in the observed spectrum.\n",
    "fc = 0.05 \n",
    "\n",
    "N = int(np.ceil((4 / b)))\n",
    "if not N % 2:  # N must be odd\n",
    "    N += 1\n",
    "n = np.arange(N)\n",
    " \n",
    "# Compute sinc filter and Blackman window. Multiply filter \n",
    "# by window and normalize to get unity gain.\n",
    "filt = np.sinc(2 * fc * (n - (N - 1) / 2))\n",
    "w = 0.42 - 0.5 * np.cos(2 * np.pi * n / (N - 1)) + \\\n",
    "    0.08 * np.cos(4 * np.pi * n / (N - 1))\n",
    "filt *= w\n",
    "filt /= np.sum(filt)\n",
    "\n",
    "# Smooth\n",
    "sflux = np.convolve(p_obs.flux, filt, mode='same')\n",
    "\n",
    "p_obs = Spectrum1D(spectral_axis=p_obs.wavelength,\n",
    "                   flux=sflux,\n",
    "                   uncertainty=p_obs.uncertainty)\n",
    "\n",
    "pl.figure()\n",
    "pl.gcf().set_size_inches((8.,4.))\n",
    "pl.xlim(sp_xlim)\n",
    "pl.plot(p_obs.wavelength, p_obs.flux, linewidth=0.5, label='obs')\n",
    "pl.plot(p_template.wavelength, p_template.flux, linewidth=0.5, color='r', label='template')\n",
    "pl.legend()\n",
    "pl.title('After smoothing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, lag = correlation.template_correlate(p_obs, p_template)\n",
    "\n",
    "pl.figure()\n",
    "pl.gcf().set_size_inches((8.,4.))\n",
    "pl.plot(lag, corr, linewidth=0.5)\n",
    "pl.xlim(0,300000)\n",
    "pl.xlabel(lag.unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redshift based on maximum\n",
    "index_peak = np.where(corr == np.amax(corr))[0][0]\n",
    "v = lag[index_peak]\n",
    "z = v / const.c.to('km/s')\n",
    "print(\"Peak maximum at: \", v)\n",
    "print(\"Redshift from peak maximum: \", z)\n",
    "\n",
    "# Redshift based on parabolic fit to mazimum\n",
    "\n",
    "n = 8 # points to the left or right of correlation maximum\n",
    "\n",
    "peak_lags = lag[index_peak-n:index_peak+n+1].value\n",
    "peak_vals = corr[index_peak-n:index_peak+n+1].value\n",
    "p = np.polyfit(peak_lags, peak_vals, deg=2)\n",
    "roots = np.roots(p)\n",
    "\n",
    "v_fit = np.mean(roots) * u.km/u.s # maximum lies at mid point between roots\n",
    "z = v_fit / const.c.to('km/s')\n",
    "\n",
    "print(\"\")\n",
    "print(\"Parabolic fit with maximum at: \", v_fit)\n",
    "print(\"Redshift from parabolic fit: \", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ref = 0.758 # \"true\" redshift, corresponding to 227242.6 km/s\n",
    "\n",
    "template_z = Spectrum1D(spectral_axis=template.wavelength * (1.+z), flux=template.flux)\n",
    "\n",
    "pl.figure()\n",
    "pl.gcf().set_size_inches((8.,4.))\n",
    "pl.xlim(sp_xlim)\n",
    "pl.plot(obs.wavelength, obs.flux, linewidth=0.5, label='obs')\n",
    "pl.plot(template_z.wavelength, template_z.flux, linewidth=0.5, color='r', label='template')\n",
    "pl.legend()\n",
    "pl.title('Redshifted original template and original observed spectrum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_err = (z - z_ref) / z_ref * 100.\n",
    "print(\"Error in the derived redshift: \", z_err, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
